{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0155831a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barak Obama is the 44th President of the United States.And he was born in Hawaii.He  went as a prime minister of USA in the year of 2015 .\n",
      "LOWERCASE :  barak obama is the 44th president of the united states.and he was born in hawaii.he  went as a prime minister of usa in the year of 2015 .\n",
      "REGULAR EXP-1 :  barak obama is the Forty Forthth president of the united states.and he was born in hawaii.he  went as a prime minister of usa in the year of 2015 .\n",
      "REGULAR EXP-2 :  **r** o**** *s t** 44t* pr*s***nt o* t** un*t** st*t*s.*n* ** w*s *orn *n **w***.**  w*nt *s * pr*** **n*st*r o* us* *n t** y**r o* 2015 .\n",
      "REGULAR EXP-3 :  barak obama is the 44th president of the united states.and he was born in hawaii.he  went as a prime minister of usa in the year of 2015 .\n",
      "WORD TOKENS :  ['Barak', 'Obama', 'is', 'the', '44th', 'President', 'of', 'the', 'United', 'States.And', 'he', 'was', 'born', 'in', 'Hawaii.He', 'went', 'as', 'a', 'prime', 'minister', 'of', 'USA', 'in', 'the', 'year', 'of', '2015', '.']\n",
      "SENTENCE TOKENS :  ['Barak Obama is the 44th President of the United States.And he was born in Hawaii.He  went as a prime minister of USA in the year of 2015 .']\n",
      "1\n",
      "Barak Obama 44th President United States.And born Hawaii.He went prime minister USA year 2015 .\n"
     ]
    }
   ],
   "source": [
    "input = \"Barak Obama is the 44th President of the United States.And he was born in Hawaii.He  went as a prime minister of USA in the year of 2015 .\"\n",
    "\n",
    "print(input)\n",
    "\n",
    "\n",
    "lowercase = input.lower()\n",
    "print(\"LOWERCASE : \",lowercase)\n",
    "\n",
    "import re\n",
    "lowercase_re = re.sub(\"44\", \"Forty Forth\", lowercase)\n",
    "print(\"REGULAR EXP-1 : \",lowercase_re)\n",
    "\n",
    "lowercase_re1 = re.sub(\"[a-m]\", \"*\",lowercase)\n",
    "print(\"REGULAR EXP-2 : \", lowercase_re1)\n",
    "\n",
    "lowercase_re2 = re.sub(\"/d\",\"-\", lowercase)\n",
    "print(\"REGULAR EXP-3 : \", lowercase)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "\n",
    "\n",
    "word_tokens = word_tokenize(input)\n",
    "print(\"WORD TOKENS : \", word_tokens)\n",
    "\n",
    "sent_tokens = sent_tokenize(input)\n",
    "print(\"SENTENCE TOKENS : \", sent_tokens)\n",
    "print(len(sent_tokens))\n",
    "\n",
    "\n",
    "\n",
    "# stop words\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "tokens_stopwords = []\n",
    "\n",
    "for token in word_tokens:\n",
    "    if token not in stop_words:\n",
    "        tokens_stopwords.append(token)\n",
    "print(\" \".join(tokens_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea33c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Words :  ['barak', 'obama', '44th', 'presid', 'unit', 'states.and', 'born', 'hawaii.h', 'went', 'prime', 'minist', 'usa', 'year', '2015', '.']\n"
     ]
    }
   ],
   "source": [
    "# stemmer\n",
    "\n",
    "stemming = [ ]\n",
    "from nltk import PorterStemmer\n",
    "\n",
    "for word in tokens_stopwords:\n",
    "    stemming.append(PorterStemmer().stem(word))\n",
    "print(\"Stemmed Words : \", stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c357a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized Words :  ['Barak', 'Obama', '44th', 'President', 'United', 'States.And', 'born', 'Hawaii.He', 'went', 'prime', 'minister', 'USA', 'year', '2015', '.']\n"
     ]
    }
   ],
   "source": [
    "#lemmatizer\n",
    "\n",
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "lemmatized_words = []\n",
    "\n",
    "for word in tokens_stopwords:\n",
    "    lemmatized_words.append(WordNetLemmatizer().lemmatize(word))\n",
    "\n",
    "print(\"Lemmatized Words : \", lemmatized_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9590f341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
